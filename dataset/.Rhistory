testData<-iris[ind==2,]
dim(trainData)
dim(testData)
table(trainData$Species)
table(testData$Species)
set.seed(54321)
ordem=sample(nrow(cpus))
tam_treino=2/3*nrow(cpus)
ind_tr=ordem[1:tam_treino]
ind_ts=ordem[(tam_treino+1):nrow(cpus)]
cpuTr=cpus[ind_tr,]
cpuTs=cpus[ind_ts,]
dim(cpuTr)
dim(cpuTs)
mean(cpuTr$perf)
mean(cpuTs$perf)
#metodo dos k vizinhos mais proximos
library(class)
knn_pred=knn(trainData[,1:4],testData[,1:4],trainData$Species)
knn_pred
t=table(knn_pred, testData$Species)## matriz de confusão
t
pecc=sum(knn_pred==testData$Species)/length(testData$Species)
pecc
vp_versicolor=t[2,2]
vn_versicolor=t[1,1]+t[3,3]
fp_versicolor=t[2,1]+t[2,3]
fn_versicolor=t[1,2]+t[3,2]
sensib_versicolor=vp_versicolor/(vp_versicolor+fn_versicolor)
sensib_versicolor
especif_versicolor=vn_versicolor/(vn_versicolor+fp_versicolor)
especif_versicolor
#Exemplo Naive Bayes
library(e1071)
model=naiveBayes(Species~.,trainData)# "Species" var independente "." todas as outras
nb_pred=predict(model,testData)
nb_pred
table(nb_pred,testData$Species)
sum(nb_pred==testData$Species)/length(testData$Species)
#Árvore de decisão: exemplo em R
library(party)
iris_ctree<- ctree(Species ~., data=trainData)
print(iris_ctree)
plot(iris_ctree)
testPred <- predict(iris_ctree, testData)
testPred[1]
table(testPred, testData$Species)
sum(testPred==testData$Species)/length(testData$Species)
formula <- Species ~ Sepal.Length + Sepal.Width + Petal.Length
iris_ctree2 <- ctree(formula , data=trainData)
plot(iris_ctree2)
testPred2 <- predict(iris_ctree2, testData)
table(testPred2, testData$Species)
sum(testPred2==testData$Species)/length(testData$Species)
# Árvores em R – package tree
library(tree)
tree1 <- tree(Species ~ Sepal.Width + Petal.Width, data=iris)
plot(tree1)
text(tree1)
plot(iris$Petal.Width,iris$Sepal.Width,pch=19,col=as.numeric(iris$Species))
partition.tree(tree1,label="Species",add=TRUE)
legend(1.75,4.5,legend=unique(iris$Species),col=unique(as.numeric(iris$Species)),pch=19)
length(iris$Species) - sum(val_prev == iris$Species)
val_prev = predict(tree1,iris, type="class")
plot(jitter(iris$Petal.Width),jitter(iris$Sepal.Width),pch=19,col=as.numeric(iris$Species))
partition.tree(tree1,label="Species",add=TRUE)
legend(1.75,4.5,legend=unique(iris$Species),col=unique(as.numeric(iris$Species)),pch=19)
tree2 = prune.tree(tree1, best = 3)
plot(tree2)
text(tree2)
val_prev = predict(tree2,iris, type="class")
sum(val_prev != iris$Species)
#Árvores de regressão: exemplo
library(rpart)
arvreg = rpart(perf ~ syct + mmin + mmax + chmax + chmin,data = cpuTr)
plot(arvreg)
text(arvreg)
val_prev = predict(arvreg, cpuTs)
val_prev
rmse(val_prev, cpuTs$perf)
mad(val_prev, cpuTs$perf)
#Exemplo: Regras em R
library(caret)
library(RWeka)
library(e1071)
model_reg = train(trainData[,1:4], trainData[,5], method = "JRip")
model_reg$finalModel
summary(model_reg$finalModel)
val_prev_reg = predict(model_reg, testData)
val_prev_reg
table(val_prev_reg, testData$Species)
#Exemplo: regressão linear múltipla
ml = lm(perf ~ syct + mmin + mmax + chmax + chmin + cach,data = cpuTr)
round(coef(ml), 2)
summary(aov(ml))
#Exemplo: regressão linear
prev_ml = predict(ml, cpuTs)
prev_ml
xlim = range(cpuTs$perf)
plot(prev_ml ~ cpuTs$perf, data=cpus, xlab = "Observados", ylab ="Previstos", xlim = xlim, ylim = xlim)
abline(0, 1, col="red")
#calculo do erro
rmse(prev_ml,cpuTs$perf)
mad(prev_ml,cpuTs$perf)
# PLS - exemplos
library(pls)
ncomps = 4
pls.cpus = plsr(perf ~ syct + mmin + mmax + chmax + chmin + cach,data = cpuTr, ncomp = ncomps)
pred.pls = predict(pls.cpus, cpuTs)[,,ncomps]
rmse(pred.pls, cpuTs$perf)
mad(pred.pls, cpuTs$perf)
pls.iris = plsda(trainData[1:4], trainData[,5])
pred.pls.iris = predict(pls.iris, testData[1:4])
pecc(pred.pls.iris, testData$Species)
table(pred.pls.iris, testData$Species)
# Análise discriminante - exemplo
lda.modelo = lda(Species ~., trainData)
lda.modelo
test.lda <- predict(lda.modelo, testData)
test.lda$class
pecc(test.lda$class, testData$Species)
#SVM - exemplos
library(e1071)
modelsvm = svm(Species ~ ., trainData)
svm_pred = predict(modelsvm, testData)
svm_pred
table(svm_pred, testData$Species)
sum(svm_pred==testData$Species)/length(testData$Species)
svm.cpus = svm(perf ~ syct + mmin + mmax + chmax + chmin + cach,data = cpuTr)
pred.svm.cpu = predict(svm.cpus, cpuTs)
rmse(pred.svm.cpu, cpuTs$perf)
mad(pred.svm.cpu, cpuTs$perf)
# Redes neuronais artificiais RNA - exemplo
library(nnet)
set.seed(123451)
nn = nnet(trainData$Species~ . ,trainData, size=5)
nn_prev = predict(nn, testData, type = "class")
table(nn_prev, testData$Species)
sum(nn_prev==testData$Species)/length(testData$Species)
nn_prev
# Random Forests (RFs) - exemplo
library(randomForest)
set.seed(12345)
iris.rf = randomForest(Species ~ ., data=trainData, importance=TRUE)
pred.rf = predict(iris.rf, testData)
pecc(pred.rf, testData$Species)
table(pred.rf, testData$Species)
"run.leave.oneout" = function(dataset, formula, index.output = ncol(dataset))
{
pred.values = factor(levels=levels(dataset[[index.output]]))
for(i in 1:nrow(dataset))
{
model = rpart(formula, data=dataset[-i,], method = "class")
pred.values[i] = predict(model, dataset[i,], type="class")
}
pred.values
}
"pecc" = function(obs, pred) sum(obs == pred) / length(pred)
pecc=function(obs,pred)
sum(obs==pred)/length(obs)
pecc(pred.rf, testData$Species)
library(randomForest)
set.seed(12345)
iris.rf = randomForest(Species ~ ., data=trainData, importance=TRUE)
pred.rf = predict(iris.rf, testData)
pecc(pred.rf, testData$Species)
table(pred.rf, testData$Species)
"run.leave.oneout" = function(dataset, formula, index.output = ncol(dataset))
{
pred.values = factor(levels=levels(dataset[[index.output]]))
for(i in 1:nrow(dataset))
{
model = rpart(formula, data=dataset[-i,], method = "class")
pred.values[i] = predict(model, dataset[i,], type="class")
}
pred.values
}
"pecc" = function(obs, pred) sum(obs == pred) / length(pred)
pecc(pred.rf, testData$Species)
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainDataIris = iris[inTrain,]
testDataIris = iris[-inTrain,]
nrow(trainDataIris)
nrow(testDataIris)
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
preds_iris_lda = predict(iris_model_lda, testDataIris[,1:4])
preds_iris_lda
confusionMatrix(preds_iris_lda, testDataIris[,5])
iris_lda_cv = train(iris[,1:4], iris[,5], method = "lda", trControl
= trainControl(method = "cv"))
iris_lda_cv$results
iris_lda_cv$resample
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainDataIris = iris[inTrain,]
testDataIris = iris[-inTrain,]
nrow(trainDataIris)
nrow(testDataIris)
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
iris_model_lda$results
preds_iris_lda = predict(iris_model_lda, testDataIris[,1:4])
preds_iris_lda
confusionMatrix(preds_iris_lda, testDataIris[,5])
# Exemplos Caret - validação cruzada
iris_lda_cv = train(iris[,1:4], iris[,5], method = "lda", trControl
= trainControl(method = "cv"))
iris_lda_cv$results
iris_lda_cv$resample
cv.ctrl = trainControl("cv", number = 5)
iris_ann = train(Species ~., data = trainDataIris,
method = "nnet", tuneLength=5, trControl = cv.ctrl,
preProc = c("center", "scale"))
iris_ann
iris_ann = train(Species ~., data = trainDataIris,
method = "nnet", tuneLength=5, trControl = cv.ctrl,
preProc = c("center", "scale"))
iris_ann
model_cv_reg = train(cpus[,c("syct", "mmin", "mmax", "chmax",
"chmin", "cach")], cpus[,"perf"], method = "M5Rules", trControl =
trainControl(method = "repeatedcv", repeats=10))
model_cv_reg$results
library(RWeka)
data(iris)
dim(iris)
head(iris)
View(iris)
View(iris)
data(iris)
dim(iris)
head(iris)
class(iris$Species)
names(iris)
library(MASS)
data(cpus)
dim(cpus)
names(cpus)
class(cpus$perf)
pecc=function(obs,pred)
sum(obs==pred)/length(obs)
rmse=function(obs,pred) sqrt(mean((obs-pred)^2))
mad=function(obs,pred) mean(abs(obs-pred))
set.seed(12345)#gerador do numero aleatorio no mesmo estado para replicar resultados
ind<-sample(2, nrow(iris), replace=TRUE, prob=c(0.7,0.3))# valor 1 aparece com 70% de prob e o 0 com 30% de prob
trainData<-iris[ind==1,]
testData<-iris[ind==2,]
dim(trainData)
dim(testData)
table(trainData$Species)
table(testData$Species)
data(iris)
dim(iris)
head(iris)
class(iris$Species)
names(iris)
pecc=function(obs,pred)
sum(obs==pred)/length(obs)
rmse=function(obs,pred) sqrt(mean((obs-pred)^2))
mad=function(obs,pred) mean(abs(obs-pred))
set.seed(12345)#gerador do numero aleatorio no mesmo estado para replicar resultados
ind<-sample(2, nrow(iris), replace=TRUE, prob=c(0.7,0.3))# valor 1 aparece com 70% de prob e o 0 com 30% de prob
trainData<-iris[ind==1,]
testData<-iris[ind==2,]
dim(trainData)
dim(testData)
table(trainData$Species)
table(testData$Species)
table(ind)
trainData<-iris[ind==1]
trainData<-iris[ind==,1]
trainData<-iris[ind==1,]
biocLite(“limma”)
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite("limma")
biocLite("ALL")
library(ALL)
data(ALL)
data(ALL)
ALL
dim(ALL)
exp=exprs(ALL)
dim(exp)
class(exp)
exp[1,1:5]
sampleNames(ALL)[1:5]
featureNames(ALL)[1:5]
varMetadata(ALL)
ALL$sex
annotation(ALL)
experimentData(ALL)
abstract(ALL)
subALL
subALL=ALL[2:4,4:7]
subALL
females=ALL[, ALL$sex=="F"]
females
anyB=grep("^B", ALL$BT) #amostras em que o 1º caracter é B
anyB
ALL[, anyB]
exp=exprs(ALL)
exp[2:3, 4:5]
library(genefilter)
install.packages("genefilter")
exp=exprs(ALL)
maximos=apply(exp,1,max)
minimos=aplly(exp,1,min)
minimos=apply(exp,1,min)
vl=maximos/minimos>2
ALLm2=ALL[vl,]
ALLm2
s=which(as.character(ALL$mol.bio)%in%c("BCR/ABL","NEG"))
ALLs=ALLm2[,s]
ALLs
ALLs$mol.bio=factor(ALLs$mol.bio)
table(ALLs$mol.bio)
s=which(as.character(ALL$mol.biol)%in%c("BCR/ABL","NEG"))
ALLs=ALLm2[,s]
ALLs
ALLs$mol.bio=factor(ALLs$mol.biol)
table(ALLs$mol.biol)
maximos=apply(exp,1,max)
minimos=apply(exp,1,min)
vl=maximos/minimos>2
ALLm2=ALL[vl,]
ALLm2
s=which(as.character(ALL$mol.biol) %in% c("BCR/ABL","NEG"))
ALLs=ALLm2[,s]
ALLs
ALLs$mol.bio=factor(ALLs$mol.biol)
ALLs$mol.biol=factor(ALLs$mol.biol)
table(ALLs$mol.biol)
tt=rowttest(ALLs, "mol.biol")
tt=rowttests(ALLs, "mol.biol")
library(limma)
design=model.matrix(~ALLm2$mol.biol)
fit=lmFit(ALLm2,design)
fit2=eBayes(fit)
diff=topTable(fit2, coef=2, 10)
diff
unlist(mget(rownames(diff), hgu95av2SYMBOL))
biocLite("hgu95av2.db")
library(hgu95av2.db)
unlist(mget(g, hgu95av2SYMBOL))
library(genefilter)
install.packages("genefilter")
biocLite("genefilter")
library(genefilter)
exp=exprs(ALL)
sds=rowSds(exp)#calcula o desvio padrao por linha
m=median(sds)
hist(sds, breaks=50, col="misttyrose")
hist(sds, breaks=50, col="mistyrose")
abline(v=m, com="blue", lwd=4, lty=2)
abline(v=m, col="blue", lwd=4, lty=2)
abline(v=m*2, col="red", lwd=4, lty=2)
ALLr=ALL[sds >= 3*m, ]
ALLr=ALL[sds >= 3*m, ]
ALLr
maximos=apply(exp,1,max)
minimos=apply(exp,1,min)
vl=maximos/minimos>2
ALLm2=ALL[vl,]
ALLm2
s=which(as.character(ALL$mol.biol) %in% c("BCR/ABL","NEG"))
ALLs=ALLm2[,s]
ALLs
ALLs$mol.biol=factor(ALLs$mol.biol)
table(ALLs$mol.biol)
tt=rowttests(ALLs, "mol.biol")
names(tt)
tt$p.value
rank=order(tt$p.value)
p20=rank[1:20]
tt$p.value[p20]
g=featureNames(ALLm2[p20])
g
annotation(ALL)
biocLite("hgu95av2.db")
library(hgu95av2.db)
unlist(mget(g, hgu95av2SYMBOL))
library(limma)
design=model.matrix(~ALLm2$mol.biol)
fit=lmFit(ALLm2,design)
fit2=eBayes(fit)
diff=topTable(fit2, coef=2, 10)
diff
unlist(mget(rownames(diff), hgu95av2SYMBOL))
biocLite("pd.hugene.1.0.st.v1")
library(ALL)
biocLite("pd.hugene.1.0.st.v1")
biocLite("genefilter")
biocLite("genefilter")
install.packages("biocLite")
biocLite("pd.hugene.1.0.st.v1")
library(pd.hugene.1.0.st.v1)
source("http://bioconductor.org/biocLite.R")
biocLite("pd.hugene.1.0.st.v1")
Install.packages(“rmarkdown”)
Install.packages("rmarkdown")
install.packages("rmarkdown")
sqrt(9)
library(pd.hugene.1.0.st.v1)
data(pd.hugene.1.0.st.v1)
data(GSM1446286_Can1.CEL)
data("GSM1446286_Can1.CEL")
biocLite("pd.hugene.1.0.st.v1")
source("http://bioconductor.org/biocLite.R")
biocLite("pd.hugene.1.0.st.v1")
library(pd.hugene.1.0.st.v1)
data(pd.hugene.1.0.st.v1)
annotation(pd.hugene.1.0.st.v1)
dim(pd.hugene.1.0.st.v1)
exp = exprs(pd.hugene.1.0.st.v1)
experimentData(pd.hugene.1.0.st.v1)
data(HuGene-1_0-st-v1)
biocLite("affy")
library(affy)
data(GSM1446294_Tot3.cel)
data("GSM1446294_Tot3.cel")
data("GSM1446294_Tot3")
# #source("http://bioconductor.org/biocLite.R")
source("http://bioconductor.org/biocLite.R")
biocLite("pd.hugene.1.0.st.v1")
library(pd.hugene.1.0.st.v1)
biocLite("affy")
library(affy)
data(pd.hugene.1.0.st.v1)
source("http://bioconductor.org/biocLite.R")
library(pd.hugene.1.0.st.v1)
setwd("~/GitHub/Data_Analysis/dataset")
library(oligo)
celFiles <- list.celfiles()
affyRaw <- read.celfiles(celFiles)
eset <- rma(affyRaw)#normalização dos dados
>biocLite("pd.hugene.1.0.st.v1.db")
biocLite("pd.hugene.1.0.st.v1.db")
14/2
10/7
my_frame <- data.frame(exprs(eset))
View(my_frame)
library(genefilter)
sds=rowSds(my_frame)#calcula o desvio padrao por linha
sds[1:15] #Ver os primeiros 15 desvios padroes
m=median(sds)#mediana de desvios de padroes 0.2639786
mean(sds)#media de desvios de padroes 0.2639786
hist(sds, breaks=20, col="mistyrose") # histograma
abline(v=m, col="blue", lwd=4, lty=2)#mediana
abline(v=m*2, col="red", lwd=4, lty=2)#limite superior 2 vezes a mediana
new_frame=my_frame[sds >= 2*m, ]
maximos=apply(my_frame,1,max)# maximos do valor de expressao dos genes
maximos
minimos=apply(my_frame,1,min)# minimo do valor de expressao dos genes
#maximo valor de gene expression
max(maximos)
#minimo valor de gene expression
min(minimos)
vl=maximos/minimos>2
new_frame2=my_frame[vl,]#Data frame filtrado com  genes cujo rácio do máximo valor sobre o mínimo valor de expressão seja superior a 2
## keep top 50 percent
filter=varFilter(eset, var.func=IQR, var.cutoff=0.5, filterByQuantile=TRUE)
frame_var_filter <- data.frame(exprs(filter))
## Expressão diferencial
require(Biobase)
object<-new("ExpressionSet", exprs=as.matrix(new_frame2))# transformar o newframe2 em  expression set
tt = rowttests(object)#Realiza os t-tests e verificar os p-values
pvalueorder= tt[order(tt$p.value),]
pvalueorder$p.value[1:20]# primeiros 20 resultados com menor p value
library(limma)
design = model.matrix(~new_frame2$GSM1446286_Can1.CEL )
fit = lmFit(new_frame2,design)
fit2 = eBayes(fit)
rank= pvalueorder$pvalue
p20 = rank[1:20]
eucD = dist(exprs(new_frame2[1:20]))
p20 = rank[1:20]
eucD = dist(exprs(new_frame2[1:20]))
eucD = dist(exprs(object[1:20]))
cl.hier <- hclust(eucD)
plot(cl.hier)
cl.hier <- hclust(eucD, method="single")
plot(cl.hier)
cl.hier <- hclust(eucD)
plot(cl.hier)
cl.hier <- hclust(eucD, method="single")
plot(cl.hier)
cl.hier <- hclust(eucD, method="average")
plot(cl.hier)
cl.hier <- hclust(eucD)
plot(cl.hier)
cl.hier <- hclust(eucD, method="single")
plot(cl.hier)
cl.hier <- hclust(eucD)
plot(cl.hier)
cl.hier <- hclust(eucD, method="average")
plot(cl.hier)
cl.hier <- hclust(eucD, method="single")
plot(cl.hier)
cl.hier <- hclust(eucD)
plot(cl.hier)
cl.hier <- hclust(eucD, method="single")
plot(cl.hier)
heatmap(exprs(object[1:20]), labCol = F)
#kmeans
km = kmeans(exprs(object[1:20]), 3)
names(km)
km$cluster
eucD = dist(exprs(object[1:20]))
cl.hier <- hclust(eucD)
plot(cl.hier)
