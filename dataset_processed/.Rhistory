View(x)
co2=data.frame(co2)
co2=data.frame(co2)
co2=data(co2)
x=data(co2)
data(co2)
data(co2)
dim(co2)
data(co2)
dim(co2)
data(CO2)
dim(CO2)
View(CO2)
View(CO2)
NAMES(CO2)
names(CO2)
CO2$Treatment
CO2$Treatment="chilled"
X=CO2$Treatment="chilled"
X=(CO2$Treatment=="chilled")
X=SUM(CO2$Treatment=="chilled")
X=sum(CO2$Treatment=="chilled")
sum(CO2$Treatment=="chilled")
data(CO2)
dim(CO2)
names(CO2)
sum(CO2$Treatment=="chilled")
help(CO2)
set.seed(1234)
x	=	rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y	=	rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
set.seed(1234)
x	=	rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y	=	rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
set.seed(1234)
x	=	rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y	=	rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
plot(x,y,col="blue",pch=19,cex=2)
text(x+0.05,y+0.05,labels=as.character(1:12))
dataFrame <- data.frame(x=x,y=y)
View(dataFrame)
dist(dataFrame)
m=dist(dataFrame)
m
dist(dataFrame)
distxy	=	dist(dataFrame,	method	=	"euclidean")
hc	=	hclust(distxy)
plot(hc)
plot(hc)
iris.sc = scale(iris[,1:4])
boxplot(iris[,1:4])
boxplot(iris.sc)
dist.iris = dist(iris.sc, method = "euclidean")
hc.complete = hclust(dist.iris, method = "complete")
my.plot.hc (hc.complete,
my.plot.hc (hc.complete,lab.col = as.integer(iris$Species)+1, cex = 0.4)
iris.sc = scale(iris[,1:4])
boxplot(iris[,1:4])
boxplot(iris.sc)
dist.iris = dist(iris.sc, method = "euclidean")
hc.complete = hclust(dist.iris, method = "complete")
my.plot.hc (hc.complete,lab.col = as.integer(iris$Species)+1, cex = 0.4)
my.plot.hc(hc.complete,lab.col = as.integer(iris$Species)+1, cex = 0.4)
hc.average = hclust(dist.iris, method = "average")
my.plot.hc (hc.average,
lab.col = as.integer(iris$Species)+1, cex = 0.4)
my.plot.hc (hc.average,lab.col = as.integer(iris$Species)+1, cex = 0.4)
my.plot.hc = function(hclust, lab = 1:length(hclust$order),
lab.col = rep(1, length(hclust$order)),
hang = 0.1, ...)
{
y = rep(hclust$height, 2)
x = as.numeric(hclust$merge)
y = y[which(x<0)]
x = x[which(x<0)]
x = abs(x)
y = y[order(x)]
x = x[order(x)]
plot(hclust, labels = F, hang = hang, ...)
text(x = x, y = y[hclust$order]- (max(hclust$height) * hang),
labels = lab[hclust$order], col = lab.col[hclust$order],
srt = 90, adj = c(1,0.5), xpd = NA, ...)
}
iris.sc = scale(iris[,1:4])
boxplot(iris[,1:4])
boxplot(iris.sc)
dist.iris = dist(iris.sc, method = "euclidean")
hc.complete = hclust(dist.iris, method = "complete")
my.plot.hc(hc.complete,lab.col = as.integer(iris$Species)+1, cex = 0.4)
hc.average = hclust(dist.iris, method = "average")
my.plot.hc (hc.average,lab.col = as.integer(iris$Species)+1, cex = 0.4)
x1	=	rnorm(12,mean=rep(1:3,each=4),sd=0.2)
x2	=	rnorm(12,mean=rep(1:3,each=4),sd=0.2)
y1	=	rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
y2	=	rnorm(12,mean=rep(c(1,2,1),each=4),sd=0.2)
df2	=	data.frame(x1,	x2,	y1,	y2)
heatmap(as.matrix(df2))
heatmap(as.matrix(df2))
library(â€œclusterâ€)
library("cluster")
diana (distxy)
resKmeans <- kmeans(dataFrame,centers=3)
library("cluster")
diana (distxy)
kmeans.iris = kmeans(iris[,1:4], centers = 3, nstart = 10000)
table(kmeans.iris$cluster, iris$Species)
resKmeans <- kmeans(dataFrame,centers=3)
download.file("https://spark-public.s3.amazonaws.com/
dataanalysis/face.rda", destfile="face.rda", method = "curl")
download.file("https://spark-public.s3.amazonaws.com/dataanalysis/face.rda", destfile="face.rda", method = "curl")
download.file("https://spark-public.s3.amazonaws.com/dataanalysis/face.rda", destfile="face.rda", method = "curl")
download.file("https://spark-public.s3.amazonaws.com/dataanalysis/face.rda", destfile="face.rda")
load("face.rda")
image(t(faceData)[,nrow(faceData):1])
svd1 <- svd(scale(faceData))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia
explicadaâ€)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicadaâ€)
svd1 <- svd(scale(faceData))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicadaâ€)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicadaâ€))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicadaâ€)
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicada" )
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicada")
download.file("https://spark-public.s3.amazonaws.com/dataanalysis/face.rda", destfile="face.rda")
load("face.rda")
image(t(faceData)[,nrow(faceData):1])
svd1 <- svd(scale(faceData))
plot(svd1$d^2/sum(svd1$d^2),pch=19,xlab="SV",ylab="Variancia explicada")
aprox1 <- svd1$u[,1] %*% t(svd1$v[,1]) * svd1$d[1]
aprox5 <- svd1$u[,1:5] %*% diag(svd1$d[1:5])%*% t(svd1$v[,
1:5])
aprox10 <- svd1$u[,1:10] %*% diag(svd1$d[1:10])%*% t(svd1$v[,
1:10])
par(mfrow=c(1,4))
image(t(aprox1)[,nrow(aprox1):1])
image(t(aprox5)[,nrow(aprox5):1])
image(t(aprox10)[,nrow(aprox10):1])
image(t(faceData)[,nrow(faceData):1])
x=(75*7)+(75*9)+(225*4)+(100*11)+(250*10)
x=(75*7)+(75*9)+(225*4)+(100*11)+(250*10)
x=(75*7)+(75*9)+(225*4)+(100*11)+(250*10)
y=(150*4)+(225*4)+(75*8)+(75*6)+(100*10)+(100*11)
data(iris)
dim (iris)
data(iris)
dim (iris)
View(iris)
class(iris$$Species)
View(iris)
class(iris$Species)
class(iris$Species)
names(iris)
library(mass)
library(MASS)
data(cpus)
dim(cpus)
names(cpus)
class(cpus$perf)
set.seed(12345)
ind <- sample(2,nrow(iris),replace=TRUE,prob=c(0.7,0.3))
trainData <- iris[ind==1,]
testData <- iris[ind==2,]
dim(trainData)
dim (testData)
table(trainData$Species)
table(testData$Species)
View(trainData)
View(testData)
View(trainData)
View(iris)
View(testData)
View(trainData)
set.seed(54321)
ordem = sample(nrow(cpus))
tam_treino=2/3*nrow(cpus)
ind_tr = ordem [1:tam_treino]
ind_ts = ordem[(tam_treino+1):nrow(cpus)]
cpuTr = cpus[ind_tr,]
cpuTs = cpus[ind_ts,]
dim(cpuTr)
dim (cpuTs)
mean(cpuTr$perf)
mean(cpuTs$perf)
names( cpus)
head(cpus)
libraray(class)
knn_pred = knn(traindData[,1:4]), testData[,1:4],trainData$Species)
knn_pred = knn(traindData[,1:4]), testData[,1:4],trainData$Species)
knn_pred = knn(traindData[,1:4]), testData[,1:4], trainData$Species)
knn_pred = knn(trainData[,1:4]), testData[,1:4], trainData$Species)
libraray(class)
library(class)
knn_pred = knn(trainData[,1:4]), testData[,1:4], trainData$Species)
library(class)
knn_pred = knn(trainData[,1:4]), testData[,1:4], trainData$Species)
knn_pred = knn(trainData[,1:4], testData[,1:4],
trainData$Species)
knn_pred
t = table(knn_pred,testData$Species)
t
pecc = sum (knn_pred==testData$Species)/lenght(testData$Species)
pecc = sum (knn_pred==testData$Species)/length(testData$Species)
pecc
vp_versicolor = t[2,2]
vn_versicolor = t[1,1] + t[3,3]
fp_versicolor = t[2,1] + t [2,3]
fn_versicolor = t[1,2]+t[3,2]
sensib_versicolor = vp_versicolor/(vp_versicolor+fn_versicolor)
sensib_versicolor
especif_versicolor = vn_versicolor/(vn_versicolor+fp_versicolor)
especif_versicolor
library (e1071)
install.packages("e1071")
library (e1071)
model = naiveBayes(Species ~ .,trainData)
nb_pred = predict(model, testData)
nb_pred
table(nb_pred, testData$Species)
sum(nb_pred==testData$Species)/length(testData$Species)
"create.cvindexes" = function(dataset, k = 5)
{
order = sample(1:nrow(dataset))
res = (order %% k) + 1
}
cv.indexes.iris = create.cvindexes(iris, 10)
table(cv.indexes.iris)
"run.cv.classif" = function(dataset, k, formula, index.output = ncol(dataset) )
{
require(rpart)
cv.indexes = create.cvindexes(dataset, k)
pred.values = factor(levels=levels(dataset[[index.output]]))
for (i in 1:k)
{
model = rpart(formula, data=dataset[cv.indexes!=i,], method = "class")
tst.indexes = which(cv.indexes==i)
pred.values[tst.indexes] = predict(model, dataset[tst.indexes,], type="class")
}
pred.values
}
pred.vals = run.cv.classif(iris, 5, Species~.)
pred.vals
sum(pred.vals == iris$Species) / nrow(iris)
"run.cv.regression" = function(dataset, k, formula)
{
require(rpart)
cv.indexes = create.cvindexes(dataset, k)
pred.values = c()
for (i in 1:k)
{
model = rpart(formula, data=dataset[cv.indexes!=i,])
tst.indexes = which(cv.indexes==i)
pred.values[tst.indexes] = predict(model, dataset[tst.indexes,])
}
pred.values
}
"rmse" = function(obs, pred) sqrt(mean((obs-pred)^2))
"mad" = function(obs, pred) mean(abs(obs-pred))
pred.values.cpus=run.cv.regression(cpus,5,perf~syct + mmin+ mmax +chmax+chmin+ cach)
"run.cv.regression" = function(dataset, k, formula)
{
require(rpart)
cv.indexes = create.cvindexes(dataset, k)
pred.values = c()
for (i in 1:k)
{
model = rpart(formula, data=dataset[cv.indexes!=i,])
tst.indexes = which(cv.indexes==i)
pred.values[tst.indexes] = predict(model, dataset[tst.indexes,])
}
pred.values
}
"rmse" = function(obs, pred) sqrt(mean((obs-pred)^2))
"mad" = function(obs, pred) mean(abs(obs-pred))
pred.values.cpus=run.cv.regression(cpus,5,perf~syct + mmin+ mmax +chmax+chmin+ cach)
rmse(cpus$perf, pred.values.cpus)
"run.leave.oneout" = function(dataset, formula, index.output = ncol(dataset))
{
pred.values = factor(levels=levels(dataset[[index.output]]))
for(i in 1:nrow(dataset))
{
model = rpart(formula, data=dataset[-i,], method = "class")
pred.values[i] = predict(model, dataset[i,], type="class")
}
pred.values
}
"pecc" = function(obs, pred) sum(obs == pred) / length(pred)
pred.vals.loo = run.leave.oneout(iris, Species~.)
pecc(iris$Species, pred.vals.loo)
"pensemble"= func.on(p){p^3+3*p^2*(1-­â€p)}
pensemble(1/2)
"pensemble" = function(p){p^3+3*p^2*(1-­â€p)}
"pensemble" = function(p){p^3+3*p^2*(1-p)}
pensemble(1/2)
pensemble(1/4)
pensemble(3/4)
library(randomForest)
install.packages("randomForest")
randomForest
install.packages("randomForest")
library(randomForest)
set.seed(12345)
iris.rf = randomForest(Species ~ ., data=trainData, importance=TRUE)
pred.rf = predict(iris.rf, testData)
pecc(pred.rf, testData$Species)
table(pred.rf, testData$Species)
pred.rf setosa versicolor virginica
install.packages("caret")
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainDataIris = iris[inTrain,]
testDataIris = iris[-inTrain,]
nrow(trainDataIris)
nrow(testDataIris)
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
library (caret)
set.seed(107)
inTrain = createDataPartition(y = iris$Species, p = 0.7, list = F)
trainDataIris = iris[inTrain,]
testDataIris = iris[-inTrain,]
nrow(trainDataIris)
nrow(testDataIris)
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
Sepal.Length 0.3781484 -0.2827500
Sepal.Width 1.7592095 2.2248294
iris_model_lda = train(iris[,1:4], iris[,5], method = "lda")
iris_model_lda$finalModel
iris_model_lda$results
iris_model_lda$resample
preds_iris_lda = predict(iris_model_lda, testDataIris[,1:4])
preds_iris_lda
confusionMatrix(preds_iris_lda, testDataIris[,5])
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ")
# library(pd.hugene.1.0.st.v1)
# # biocLite("affy")
# #library(affy)
# data(pd.hugene.1.0.st.v1)
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ",widts= C(1, 2
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ",widts= C(1, 2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ",widts= C(1, 2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ", widths= C(1, 2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ", widths= C(1))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ", widths= C(1,2))
setwd("~/GitHub/Data_Analysis/dataset_processed")
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ", widths= C(1,2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = " ", )#widths= C(1,2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = "\n", widths= C(1,2))
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = "\n"
data=read.fwf(file="GSM1446286_sample_table.txt",header = TRUE , sep = "\n")
data=read.fwf(file="GSM1446286_sample_table.txt",skip=2,widths= c(1,2))
View(data)
data=read.fwf(file="GSM1446286_sample_table.txt",skip=2,widths= c(2))
View(data)
data=read.fwf(file="GSM1446286_sample_table.txt",widths= c(2))
View(data)
View(data)
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",widths= c(2))
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",widths= c(1,2))
View(data)
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE,widths= c(1,2))
View(data)
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE
# data(pd.hugene.1.0.st.v1)
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE
data=read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE)
data = read.fwf(file="GSM1446286_sample_table.txt",sep="\n",header= TRUE)
data = read.fwf(file="GSM1446286_sample_table.txt",sep="\n",header= TRUE,widths=c(1,2))
View(data)
data = read.fwf(file="GSM1446286_sample_table.txt",sep="\n",header= TRUE,widths=c(8,10)
data = read.fwf(file="GSM1446286_sample_table.txt",sep="\n",header= TRUE,widths=c(8,10))
data = read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE,widths=c(8,10))
View(data)
setwd("~/GitHub/Data_Analysis/dataset_processed")
setwd("~/GitHub/Data_Analysis/dataset_processed")
data = read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE,widths=c(8,10))
mean(data$x)
View(data)
mean(data$X)
names(data) = c("NameSeq","mcg","gvh","alm","mit","erl","pox","vac","nuc","local") #atribuiÃ§Ã£o de nomes aos atributos do dataset
class(data) #classe do ficheiro
typeof(data) #tipo do dataset
nrow(data) #numero de linhas
ncol(data) #numero de colunas
sapply(data, class) #verificar a classe de cada coluna
sapply(data, typeof) #verificar o tipo de valor que cada coluna tem
sum(is.na(data)) #verificar se tem numeros omissos - Nao tem valores omissos
table(data$local) #tabela com o numero de entidades (sequencias) que pertencem a cada local
summary(data) #resumo de todos os atributos
summary(data$x) #resumo de todos os atributos
y
summary(data$X) #resumo de todos os atributos
table(data$X) #tabela com o numero de entidades (sequencias) que pertencem a cada local
summary(data$X) #resumo de todos os atributos
pie(table(data$X)) # grÃ¡fico que dÃ¡ uma noÃ§Ã£o da quantidade de amostras em cada localizaÃ§Ã£o
summary(data$X) #resumo de todos os atributos
hist(data$X,probability=T,col=gray(.9),main="ST depression induced by exercise relative to rest",xlab="Oldpeak")
hist(data$X,probability=T,col=gray(.9),main="Analysis of compartment-specific gene expression in breast cancer tumors",xlab="Value")
boxplot(data$X,probability=T,col=gray(.9),main="Analysis of compartment-specific gene expression in breast cancer tumors",xlab="Value")
curve(dexp(x,1/mean(data$X)),add=T,col="red",lwd=1)
boxplot(data$X,probability=T,col=gray(.9),main="Analysis of compartment-specific gene expression in breast cancer tumors",xlab="Value")
curve(dexp(x,1/mean(data$X)),add=T,col="red",lwd=1)
dens = density(data$X)
m = mean(data$X)
hist(data$X,probability=T,col=gray(.9))
hist(data$X,probability=T,col=gray(.9))
lines(dens, col = "blue")
abline(v=m, col = "green")
curve(dnorm(x,mean(data$X),sd(data$X)),add=T,col="red")
dens = density(data$X)
m = mean(data$X)
hist(data$X,probability=T,col=gray(.9),main="Analysis of compartment-specific gene expression in breast cancer tumors",xlab="Value")
lines(dens, col = "blue")
abline(v=m, col = "green")
curve(dnorm(x,mean(data$X),sd(data$X)),add=T,col="red")
qqnorm(data$X, main="QQnorm Colesterol",pch=12,col="blue")
qqline(data$X, col="red", lwd=3)
qqnorm(data$X, main="QQnorm Colesterol",pch=12,col="blue")
sourceEntireFolder <- function(folderName, verbose=FALSE, showWarnings=TRUE) {
files <- list.files(folderName, full.names=TRUE)
# Grab only R files
files <- files[ grepl("\\.[rR]$", files) ]
if (!length(files) && showWarnings)
warning("No R files in ", folderName)
for (f in files) {
if (verbose)
cat("sourcing: ", f, "\n")
## TODO:  add caught whether error or not and return that
try(source(f, local=FALSE, echo=FALSE), silent=!verbose)
}
return(invisible(NULL))
}
data = read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE,widths=c(8,10))
mean(data$X)
sourceEntireFolder <- function(folderName, verbose=FALSE, showWarnings=TRUE) {
files <- list.files(folderName, full.names=TRUE)
# Grab only R files
files <- files[ grepl("\\.[rR]$", files) ]
if (!length(files) && showWarnings)
warning("No R files in ", folderName)
for (f in files) {
if (verbose)
cat("sourcing: ", f, "\n")
## TODO:  add caught whether error or not and return that
try(source(f, local=FALSE, echo=FALSE), silent=!verbose)
}
return(invisible(NULL))
}
sapply( list.files(run_all_these, full.names=TRUE), source )
m=setwd("~/GitHub/Data_Analysis/dataset_processed")
fileFun(m)
fileFun <- function(theDir) {
## Look for files (directories included for now)
allFiles <- list.files(theDir, no.. = TRUE)
## Look for directory names
allDirs <- list.dirs(theDir, full.names = FALSE, recursive = FALSE)
## If there are any directories,
if(length(allDirs)) {
## Set names for the new list
names(moreFiles) <- allDirs
## Determine files found, excluding directory names
## then call this function again
moreFiles <- lapply(file.path(theDir, allDirs), fileFun)
outFiles <- allFiles[!allFiles %in% allDirs]
## Combine appropriate results for current list
if(length(outFiles)) {
allFiles <- c(outFiles, moreFiles)
} else {
allFiles <- moreFiles
}
}
return(allFiles)
}
## Try with your directory?
m=setwd("~/GitHub/Data_Analysis/dataset_processed")
fileFun(m)
fileFun[0]
fileFun(0)
fileFun(m)
fileFun(0)
fileFun[1]
lista=fileFun(m)
lista
lista[0]
lista(0)
files = list.files(m ,recursive = T)
files
files[0]
files(1)
files[2]
files[1]
lista=fileFun(m)
m=setwd("~/GitHub/Data_Analysis/dataset_processed")
lista=fileFun(m)
m=setwd("~/GitHub/Data_Analysis/dataset_processed")
files = list.files(m ,recursive = T)
files[1]
for(i in files):{
data[i]=files[i]}
for(i in files):{
for(i in 1:dim(files)):{
for(i in 1:dim(files)):{
data1 = read.fwf(file="GSM1446286_sample_table.txt",sep=" ",header= TRUE,widths=c(8,10))
shapiro.test(data1$X)#nÃ£o Ã© normal
shapiro.test(data1$X)#nÃ£o Ã© normal
